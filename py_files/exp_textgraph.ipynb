{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6cf6a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/causal/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from graph_generator.graphparsers import RelationshipGraphParser\n",
    "from linearization_utils import *\n",
    "from retrieval_utils import similarity_search_graph_docs\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529b5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # === Embedding & VectorStore ===\n",
    "    \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",  # Embedding model for documents/questions\n",
    "    \"faiss_search_k\": 3,  # Number of nearest neighbors to retrieve from FAISS\n",
    "\n",
    "    # === LLM (text generation) ===\n",
    "    \"llm_model_id\": \"microsoft/Phi-4-mini-reasoning\",  # HuggingFace model ID\n",
    "    \"device_map\": \"auto\",  # Device placement: \"cuda\", \"mps\", \"cpu\", or \"auto\"\n",
    "    \"dtype_policy\": \"auto\",  # Precision: \"auto\", \"bf16\", \"fp16\", or \"fp32\"\n",
    "    \"max_new_tokens\": 256,  # Maximum tokens generated per response\n",
    "    \"do_sample\": True,  # Whether to use sampling (True) or greedy decoding (False)\n",
    "    \"temperature\": 0.4,  # Randomness control for sampling; lower = more deterministic\n",
    "    \"top_p\": 1.0,  # Nucleus sampling threshold; 1.0 = no restriction\n",
    "    \"return_full_text\": False,  # Return full text (input+output) if True, only output if False\n",
    "    \"seed\": None,  # Random seed for reproducibility; set to int or None\n",
    "\n",
    "    # === Prompt / Answer ===\n",
    "    \"answer_mode\": \"YES_NO\",  # Answer format mode, e.g., YES/NO\n",
    "    \"answer_uppercase\": True,  # If True → \"YES\"/\"NO\", else \"yes\"/\"no\"\n",
    "\n",
    "    # === Prompt construction ===\n",
    "    \"include_retrieved_context\": True,  # Include retrieved Q&A in prompt\n",
    "    \"include_current_triples\": True,  # Include graph triples in prompt\n",
    "}\n",
    "\n",
    "try:\n",
    "    from transformers import set_seed  # Utility for reproducibility\n",
    "except Exception:\n",
    "    set_seed = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb6946a",
   "metadata": {},
   "source": [
    "## RAG workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b281c4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vl/xzmgrvdj0gj6gtqph130n1fr0000gn/T/ipykernel_68813/2923646883.py:25: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  emb = HuggingFaceEmbeddings(model_name=CONFIG[\"embedding_model\"])  # Local embedding model (MiniLM-L6-v2, 384 dim)\n"
     ]
    }
   ],
   "source": [
    "def _select_dtype() -> torch.dtype:\n",
    "    \"\"\"Choose dtype based on CONFIG['dtype_policy'] and hardware.\"\"\"\n",
    "    policy = CONFIG.get(\"dtype_policy\", \"auto\")\n",
    "    if policy == \"bf16\":\n",
    "        return torch.bfloat16\n",
    "    if policy == \"fp16\":\n",
    "        return torch.float16\n",
    "    if policy == \"fp32\":\n",
    "        return torch.float32\n",
    "\n",
    "    # auto mode\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "    # MPS backend works more reliably with fp32\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.float32\n",
    "    return torch.float32\n",
    "\n",
    "def _yn(text_yes=\"YES\", text_no=\"NO\"):\n",
    "    return (text_yes, text_no) if CONFIG.get(\"answer_uppercase\", True) else (text_yes.lower(), text_no.lower())\n",
    "\n",
    "# =========================\n",
    "# Embeddings / Vectorstore\n",
    "# =========================\n",
    "emb = HuggingFaceEmbeddings(model_name=CONFIG[\"embedding_model\"])  # Local embedding model (MiniLM-L6-v2, 384 dim)\n",
    "\n",
    "def build_faiss_index(docs: List[Document]) -> FAISS:\n",
    "    return FAISS.from_documents(docs, emb)\n",
    "\n",
    "# =========================\n",
    "# LLM Loader\n",
    "# =========================\n",
    "def load_llm_pipeline(\n",
    "    model_id: Optional[str] = None,       # HuggingFace model id\n",
    "    device_map: Optional[str] = None,     # Device placement\n",
    "    dtype: Optional[torch.dtype] = None,  # Torch dtype\n",
    "    max_new_tokens: Optional[int] = None, # Max tokens per generation\n",
    "    temperature: Optional[float] = None,  # Sampling temperature\n",
    "    top_p: Optional[float] = None,        # Nucleus sampling threshold\n",
    "    do_sample: Optional[bool] = None,     # Sampling vs greedy\n",
    "    return_full_text: Optional[bool] = None,  # Return input+output if True\n",
    "):\n",
    "    \"\"\"\n",
    "    Return a text-generation pipeline for QA generation.\n",
    "    All defaults pull from CONFIG; any arg here will override CONFIG.\n",
    "    \"\"\"\n",
    "    model_id = model_id or CONFIG[\"llm_model_id\"]\n",
    "    device_map = device_map or CONFIG[\"device_map\"]\n",
    "    dtype = dtype or _select_dtype()\n",
    "    max_new_tokens = max_new_tokens or CONFIG[\"max_new_tokens\"]\n",
    "    temperature = CONFIG[\"temperature\"] if temperature is None else temperature\n",
    "    top_p = CONFIG[\"top_p\"] if top_p is None else top_p\n",
    "    do_sample = CONFIG[\"do_sample\"] if do_sample is None else do_sample\n",
    "    return_full_text = CONFIG[\"return_full_text\"] if return_full_text is None else return_full_text\n",
    "\n",
    "    if set_seed and isinstance(CONFIG.get(\"seed\"), int):\n",
    "        set_seed(CONFIG[\"seed\"])\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=dtype,\n",
    "        device_map=device_map,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "\n",
    "    gen_pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        device_map=device_map,\n",
    "        torch_dtype=dtype,\n",
    "        return_full_text=return_full_text,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "    return gen_pipe, tokenizer\n",
    "\n",
    "# =========================\n",
    "# Question → Graph (generic)\n",
    "# =========================\n",
    "def parse_question_to_graph_generic(parser, question: str) -> Tuple[nx.Graph, List[Dict]]:\n",
    "    \"\"\"\n",
    "    Compatible with RelationshipGraphParser.question_to_graph\n",
    "    and CausalQuestionGraphParser.question_to_causal_graph\n",
    "    \"\"\"\n",
    "    if hasattr(parser, \"question_to_graph\"):\n",
    "        return parser.question_to_graph(question)\n",
    "    elif hasattr(parser, \"question_to_causal_graph\"):\n",
    "        return parser.question_to_causal_graph(question)\n",
    "    else:\n",
    "        raise AttributeError(\"Parser must provide question_to_graph or question_to_causal_graph\")\n",
    "\n",
    "# =========================\n",
    "# Prompt Builder\n",
    "# =========================\n",
    "def make_graph_qa_prompt(\n",
    "    question: str,\n",
    "    G: nx.Graph,\n",
    "    relations: Optional[List[Dict]] = None,\n",
    "    retrieved_docs = None\n",
    ") -> str:\n",
    "    # 1) retrieved context (if any)\n",
    "    sections = []\n",
    "    if retrieved_docs and CONFIG.get(\"include_retrieved_context\", True):\n",
    "        doc0, score0 = retrieved_docs[0]\n",
    "        related_triples = doc0.page_content.strip()\n",
    "        related_answer  = doc0.metadata.get(\"llm_answer\", \"\")\n",
    "        sections.append(\n",
    "            \"<<<RETRIEVED_CONTEXT_START>>>\\n\"\n",
    "            \"The system searched for a related question in the database. Below are related question's graph triples and its prior answer as reference. \" \\\n",
    "            \"You don't have to follow it completely, just use it as a reference.\\n\"\n",
    "            f\"[RELATED QUESTION'S GRAPH TRIPLES]:\\n{related_triples}\\n\"\n",
    "            f\"[RELATED QUESTION'S ANSWER]: {related_answer}\\n\"\n",
    "            \"<<<RETRIEVED_CONTEXT_END>>>\"\n",
    "        )\n",
    "\n",
    "    # 2) current question + triples (optional)\n",
    "    triples_text = \"\"\n",
    "    if relations and CONFIG.get(\"include_current_triples\", True):\n",
    "        text = build_relationship_text(question, G, relations) \n",
    "        triples_text += text\n",
    "    \n",
    "    sections.append(\n",
    "        \"[GRAPH FORMAT DESCRIPTION]:\\n\"\n",
    "        \"The graph triples are encoded as a JSON object with three fields:\\n\"\n",
    "        \"- \\\"entity_dict\\\": A list of entity names, where the index is the entity ID.\\n\"\n",
    "        \"- \\\"relation_dict\\\": A list of relation types, where the index is the relation ID.\\n\"\n",
    "        \"- \\\"edges\\\": A list of triples [head_id, relation_id, tail_id], meaning:\\n\"\n",
    "        \"  entity_dict[head_id] -- relation_dict[relation_id] --> entity_dict[tail_id].\\n\\n\"\n",
    "        \"Example:\\n\"\n",
    "        \"{\\n\"\n",
    "        \"  \\\"entity_dict\\\": [\\\"cat\\\", \\\"chases\\\", \\\"mouse\\\"],\\n\"\n",
    "        \"  \\\"relation_dict\\\": [\\\"subj\\\", \\\"obj\\\"],\\n\"\n",
    "        \"  \\\"edges\\\": [[0,0,1], [1,1,2]]\\n\"\n",
    "        \"}\\n\"\n",
    "        \"represents:\\n\"\n",
    "        \"- cat --subj--> chases\\n\"\n",
    "        \"- chases --obj--> mouse\\n\"\n",
    "    )    \n",
    "    \n",
    "    q_block = f\"[CURRENT QUESTION]: {question}\"\n",
    "    if triples_text.strip():\n",
    "        q_block += f\"\\n[CURRENT QUESTION'S GRAPH TRIPLES]:\\n{triples_text}\"\n",
    "    sections.append(q_block)\n",
    "\n",
    "    # 3) task instructions (placed at the end)\n",
    "    yes, no = _yn(\"YES\", \"NO\")\n",
    "    rules = (\n",
    "        \"[TASK]: You are a precise QA assistant for binary (yes/no) questions.\\n\"\n",
    "        f\"- Output ONLY one token: {yes} or {no}.\\n\"\n",
    "        \"- Do NOT copy or summarize any context.\\n\"\n",
    "        \"- Do NOT show reasoning, steps, or extra words.\\n\"\n",
    "        f\"[ANSWER]: \"\n",
    "    )\n",
    "    sections.append(rules)\n",
    "\n",
    "    # Final prompt\n",
    "    prompt = \"\\n\\n\".join(sections)\n",
    "    return prompt\n",
    "\n",
    "# =========================\n",
    "# LLM Answerer\n",
    "# =========================\n",
    "def answer_with_llm(\n",
    "    question: str,\n",
    "    gen_pipe,\n",
    "    parser,\n",
    "    faiss_db = None,\n",
    "    prompt = None\n",
    ") -> str:\n",
    "    retrieved_docs = None\n",
    "    if faiss_db:\n",
    "        k = CONFIG.get(\"faiss_search_k\", 3)  # Number of docs to retrieve\n",
    "        _, hits = similarity_search_graph_docs(question, parser, faiss_db, k=k)\n",
    "        retrieved_docs = hits\n",
    "        \n",
    "    if prompt == None:\n",
    "        G, rels = parse_question_to_graph_generic(parser, question)\n",
    "        prompt = make_graph_qa_prompt(question, G, rels, retrieved_docs)\n",
    "\n",
    "    out = gen_pipe(prompt)\n",
    "    text = out[0][\"generated_text\"]\n",
    "\n",
    "    # If return_full_text=False → only new content; else trim prefix\n",
    "    if CONFIG.get(\"return_full_text\", True):\n",
    "        answer = text[len(prompt):].strip()\n",
    "    else:\n",
    "        answer = text.strip()\n",
    "\n",
    "    # Normalize YES/NO case\n",
    "    if CONFIG.get(\"answer_mode\", \"YES_NO\"):\n",
    "        yes, no = _yn(\"YES\", \"NO\")\n",
    "        a = answer.strip().lower()\n",
    "        if \"yes\" in a and \"no\" not in a:\n",
    "            answer = yes\n",
    "            print(answer)\n",
    "            return answer\n",
    "        elif \"no\" in a and \"yes\" not in a:\n",
    "            answer = no\n",
    "            print(answer)\n",
    "            return answer\n",
    "        else:\n",
    "            answer = answer_with_llm(question, gen_pipe, parser, faiss_db, prompt)\n",
    "    \n",
    "    \n",
    "\n",
    "# =========================\n",
    "# Build Docs with LLM Answer\n",
    "# =========================\n",
    "def build_docs_with_answer(\n",
    "    questions: List[str],\n",
    "    parser,\n",
    "    gen_pipe,\n",
    "    *,\n",
    "    add_prompt_snapshot: bool = False,\n",
    "    faiss_db = None\n",
    ") -> List[Document]:\n",
    "    docs: List[Document] = []\n",
    "    for qid, q in enumerate(questions, start=1):\n",
    "        G, rels = parse_question_to_graph_generic(parser, q)\n",
    "        text = build_relationship_text(q, G, rels)  # Output [QUESTION][GRAPH][TRIPLES]\n",
    "\n",
    "        # Get LLM answer\n",
    "        answer = answer_with_llm(q, gen_pipe, parser, faiss_db)\n",
    "\n",
    "        metadata = {\n",
    "            \"graph_id\": f\"Q{qid}\",\n",
    "            \"question\": q,\n",
    "            \"num_nodes\": G.number_of_nodes(),\n",
    "            \"num_edges\": G.number_of_edges(),\n",
    "            \"llm_model\": CONFIG[\"llm_model_id\"],\n",
    "            \"llm_answer\": answer,\n",
    "            \"created_at\": int(time.time()),\n",
    "        }\n",
    "        if add_prompt_snapshot:\n",
    "            metadata[\"prompt_snapshot\"] = make_graph_qa_prompt(q, G, rels)\n",
    "\n",
    "        docs.append(Document(page_content=text, metadata=metadata))\n",
    "    return docs\n",
    "\n",
    "\n",
    "def build_faiss_index(docs: List[Document]) -> FAISS:\n",
    "    vectordb = FAISS.from_documents(docs, emb)\n",
    "    return vectordb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20306aa8",
   "metadata": {},
   "source": [
    "## Text RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "295d34be",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = {\n",
    "       # --- 原始 YES 类 ---\n",
    "    \"Is the Earth, which orbits the Sun along with seven other planets in the solar system, generally considered to be round in shape despite its slight equatorial bulge?\",\n",
    "    \"Given that Earth completes a rotation approximately every 24 hours, does this rotation cause the Sun to appear to rise in the east and set in the west from the perspective of an observer on the surface?\",\n",
    "    \"Considering that Paris is the administrative and cultural center of France, is it also the official capital city of the country according to its constitution?\",\n",
    "    \"Based on basic human biology, which requires oxygen for cellular respiration and energy production, do humans need oxygen to survive under normal conditions?\",\n",
    "    \"Since the Moon is gravitationally bound to Earth and completes an orbit approximately every 27 days, is it classified as Earth's only natural satellite?\", \n",
    "\n",
    "    \"Although the Sahara Desert is one of the largest deserts in the world, is it located in the South American continent instead of Africa?\",\n",
    "    \"Even though the Amazon River is among the longest rivers globally, is it actually longer than the Nile River when measured by official geographical surveys?\",\n",
    "    \"Despite Tokyo being the largest city in Japan and a major global hub, is it the capital city of South Korea?\",\n",
    "    \"Considering the natural habitats of penguins, which are mainly located in the Southern Hemisphere, do penguins naturally live in the Arctic region alongside polar bears?\",\n",
    "    \"Although gold is a dense and valuable metal, is its density greater than that of lead, making it heavier per cubic centimeter?\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba0620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOLD_LABELS = {\n",
    "    # --- 原始 YES 类 ---\n",
    "    \"Is the Earth, which orbits the Sun along with seven other planets in the solar system, generally considered to be round in shape despite its slight equatorial bulge?\": \"YES\",\n",
    "    \"Given that Earth completes a rotation approximately every 24 hours, does this rotation cause the Sun to appear to rise in the east and set in the west from the perspective of an observer on the surface?\": \"YES\",\n",
    "    \"Considering that Paris is the administrative and cultural center of France, is it also the official capital city of the country according to its constitution?\": \"YES\",\n",
    "    \"Based on basic human biology, which requires oxygen for cellular respiration and energy production, do humans need oxygen to survive under normal conditions?\": \"YES\",\n",
    "    \"Since the Moon is gravitationally bound to Earth and completes an orbit approximately every 27 days, is it classified as Earth's only natural satellite?\": \"YES\",\n",
    "\n",
    "    # --- 原始 NO 类 ---\n",
    "    \"Although the Sahara Desert is one of the largest deserts in the world, is it located in the South American continent instead of Africa?\": \"NO\",\n",
    "    \"Even though the Amazon River is among the longest rivers globally, is it actually longer than the Nile River when measured by official geographical surveys?\": \"NO\",\n",
    "    \"Despite Tokyo being the largest city in Japan and a major global hub, is it the capital city of South Korea?\": \"NO\",\n",
    "    \"Considering the natural habitats of penguins, which are mainly located in the Southern Hemisphere, do penguins naturally live in the Arctic region alongside polar bears?\": \"NO\",\n",
    "    \"Although gold is a dense and valuable metal, is its density greater than that of lead, making it heavier per cubic centimeter?\": \"NO\",\n",
    "\n",
    "    # --- Follow-up Questions (YES/NO balanced) ---\n",
    "    # Earth shape\n",
    "    \"Despite the Earth's slightly flattened poles, is its shape closer to a sphere than to a flat surface?\": \"YES\",\n",
    "    \"Is the Earth perfectly flat with no curvature anywhere on its surface?\": \"NO\",\n",
    "\n",
    "    # Sun rotation\n",
    "    \"Given the Earth's rotation, is the apparent motion of the Sun consistent with the Sun rising in the east?\": \"YES\",\n",
    "    \"If the Earth did not rotate on its axis, would the Sun still rise and set in the same pattern as it does now?\": \"NO\",\n",
    "\n",
    "    # Paris as capital\n",
    "    \"Considering France's administrative structure, is Paris recognized as the political and economic capital of the nation?\": \"YES\",\n",
    "    \"Is Berlin, rather than Paris, designated as the official capital of France in any historical or legal record?\": \"NO\",\n",
    "\n",
    "    # Oxygen necessity\n",
    "    \"Since oxygen is vital for human life, is it correct to say that humans cannot survive without breathing air containing oxygen?\": \"YES\",\n",
    "    \"Can humans live indefinitely without any access to oxygen in their environment?\": \"NO\",\n",
    "\n",
    "    # Moon as satellite\n",
    "    \"Is the Moon the only large natural body that consistently orbits Earth in the solar system?\": \"YES\",\n",
    "    \"Do humans have multiple moons orbiting the Earth, similar to Jupiter or Saturn?\": \"NO\",\n",
    "\n",
    "    # Sahara Desert\n",
    "    \"Is the Sahara Desert geographically located across multiple countries in northern Africa?\": \"YES\",\n",
    "    \"Is the Sahara Desert primarily located in the continent of South America?\": \"NO\",\n",
    "\n",
    "    # Amazon River\n",
    "    \"Does the Nile River surpass the Amazon River in length when measured by the most widely accepted geographical data?\": \"YES\",\n",
    "    \"Is the Amazon River considered to originate in Europe according to global mapping authorities?\": \"NO\",\n",
    "\n",
    "    # Tokyo\n",
    "    \"Is Tokyo the capital city of Japan and a major economic center in Asia?\": \"YES\",\n",
    "    \"Is Tokyo officially listed as the capital city of South Korea in government documents?\": \"NO\",\n",
    "\n",
    "    # Penguins\n",
    "    \"Do penguins naturally inhabit regions in the Southern Hemisphere, particularly Antarctica?\": \"YES\",\n",
    "    \"Do penguins live alongside polar bears in the Arctic region as part of their natural habitat?\": \"NO\",\n",
    "\n",
    "    # Gold vs Lead\n",
    "    \"Is gold denser than most metals but still slightly less dense than lead?\": \"NO\",\n",
    "    \"Is gold classified as a metal due to its physical and chemical properties?\": \"YES\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "399a983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Text RAG: 仅用问题文本入库 ===\n",
    "from langchain.schema import Document\n",
    "\n",
    "def build_text_docs_with_answer(\n",
    "    questions: List[str],\n",
    "    gen_pipe,\n",
    "    *,\n",
    "    add_prompt_snapshot: bool = False,\n",
    "    text_db: Optional[FAISS] = None\n",
    ") -> List[Document]:\n",
    "    \"\"\"\n",
    "    生成仅文本 RAG 的文档，并使 metadata 字段与图 RAG 对齐：\n",
    "    - graph_id / question / num_nodes / num_edges / llm_model / llm_answer / created_at / prompt_snapshot(可选)\n",
    "    - 其中 num_nodes/num_edges 统一置 0，保持同名键方便评测与对比\n",
    "    \"\"\"\n",
    "    docs: List[Document] = []\n",
    "    for qid, q in enumerate(questions, start=1):\n",
    "        # 文本版页面内容：只存问题文本\n",
    "        page_content = f\"{q}\"\n",
    "\n",
    "        # 生成 LLM 答案（文本 RAG 检索）\n",
    "        answer = answer_with_llm_text(q, gen_pipe, text_db=text_db)\n",
    "\n",
    "        # metadata 字段与 Graph RAG 对齐\n",
    "        metadata = {\n",
    "            \"graph_id\": f\"Q{qid}\",\n",
    "            \"question\": q,\n",
    "            \"num_nodes\": 0,                    # 对齐字段\n",
    "            \"num_edges\": 0,                    # 对齐字段\n",
    "            \"llm_model\": CONFIG[\"llm_model_id\"],\n",
    "            \"llm_answer\": answer,\n",
    "            \"created_at\": int(time.time()),\n",
    "        }\n",
    "        if add_prompt_snapshot:\n",
    "            # 为了对齐，也提供 prompt_snapshot；注意这里是“文本 RAG”的 prompt\n",
    "            # 为了避免再次触发生成，这里重建与上面一致的 prompt 片段\n",
    "            prompt_snapshot = make_text_qa_prompt(q, None if not text_db else similarity_search_text_docs(q, text_db, k=CONFIG.get(\"faiss_search_k\",3))[1])\n",
    "            metadata[\"prompt_snapshot\"] = prompt_snapshot\n",
    "\n",
    "        docs.append(Document(page_content=page_content, metadata=metadata))\n",
    "    return docs\n",
    "\n",
    "\n",
    "def build_docs_text_only(questions: List[str]) -> List[Document]:\n",
    "    return [build_text_doc(q) for q in questions]\n",
    "\n",
    "def build_text_faiss_index(questions: List[str]) -> FAISS:\n",
    "    docs = build_docs_text_only(questions)\n",
    "    return FAISS.from_documents(docs, emb)\n",
    "\n",
    "# === Text RAG: 相似度检索（与入库同分布：纯问题文本） ===\n",
    "def similarity_search_text_docs(\n",
    "    user_question: str,\n",
    "    vectordb: FAISS,\n",
    "    k: int = 5,\n",
    "):\n",
    "    query_text = f\"{user_question}\"\n",
    "    results = vectordb.similarity_search_with_score(query_text, k=k)\n",
    "    return query_text, results\n",
    "\n",
    "\n",
    "# === Text RAG: Prompt（不含图三元组；可拼检索上下文的原问题文本与历史答案） ===\n",
    "def make_text_qa_prompt(\n",
    "    question: str,\n",
    "    retrieved_docs=None\n",
    ") -> str:\n",
    "    sections = []\n",
    "    if retrieved_docs and CONFIG.get(\"include_retrieved_context\", True):\n",
    "        doc0, _ = retrieved_docs[0]\n",
    "        related_q_txt = doc0.page_content.strip()\n",
    "        related_answer = (doc0.metadata or {}).get(\"llm_answer\", \"\")\n",
    "        sections.append(\n",
    "            \"<<<RETRIEVED_CONTEXT_START>>>\\n\"\n",
    "            \"The system searched for a related question in the database. Below are related question's graph triples and its prior answer as reference. \" \\\n",
    "            \"You don't have to follow it completely, just use it as a reference.\\n\"\n",
    "            f\"[RELATED QUESTION TEXT]:\\n{related_q_txt}\\n\"\n",
    "            f\"[RELATED ANSWER]: {related_answer}\\n\"\n",
    "            \"<<<RETRIEVED_CONTEXT_END>>>\"\n",
    "        )\n",
    "\n",
    "    sections.append(f\"[CURRENT QUESTION]: {question}\")\n",
    "\n",
    "    yes, no = _yn(\"YES\", \"NO\")\n",
    "    sections.append(\n",
    "        \"[TASK]: You are a precise QA assistant for binary (yes/no) questions.\\n\"\n",
    "        f\"- Output ONLY one token: {yes} or {no}.\\n\"\n",
    "        \"- Do NOT copy or summarize any context.\\n\"\n",
    "        \"- Do NOT show reasoning, steps, or extra words.\\n\"\n",
    "        f\"[ANSWER]: \"\n",
    "    )\n",
    "    return \"\\n\\n\".join(sections)\n",
    "\n",
    "def answer_with_llm_text(\n",
    "    question: str,\n",
    "    gen_pipe,\n",
    "    *,\n",
    "    text_db: Optional[FAISS] = None\n",
    ") -> str:\n",
    "    # 检索（可选）\n",
    "    retrieved_docs = None\n",
    "    if text_db:\n",
    "        k = CONFIG.get(\"faiss_search_k\", 3)\n",
    "        _, hits = similarity_search_text_docs(question, text_db, k=k)\n",
    "        retrieved_docs = hits\n",
    "\n",
    "    # Prompt\n",
    "    prompt = make_text_qa_prompt(question, retrieved_docs)\n",
    "\n",
    "    # 生成\n",
    "    out = gen_pipe(prompt)\n",
    "    text = out[0][\"generated_text\"]\n",
    "\n",
    "    # 取输出\n",
    "    if CONFIG.get(\"return_full_text\", True):\n",
    "        answer = text[len(prompt):].strip()\n",
    "    else:\n",
    "        answer = text.strip()\n",
    "\n",
    "    # 归一化 YES/NO（与现有 answer_with_llm 一致）\n",
    "    if CONFIG.get(\"answer_mode\", \"YES_NO\"):\n",
    "        yes, no = _yn(\"YES\", \"NO\")\n",
    "        a = answer.strip().lower()\n",
    "        if \"yes\" in a and \"no\" not in a:\n",
    "            answer = yes\n",
    "        elif \"no\" in a and \"yes\" not in a:\n",
    "            answer = no\n",
    "        else:\n",
    "            # 回退：保持原样（或你也可和图版一样递归一次，这里避免递归以最少改动为主）\n",
    "            answer = no  # 与“不确定选 NO”的规则一致\n",
    "    return answer\n",
    "\n",
    "def build_text_faiss_index_with_answers(\n",
    "    questions: List[str],\n",
    "    gen_pipe,\n",
    "    *,\n",
    "    add_prompt_snapshot: bool = False,\n",
    "    bootstrap_db: Optional[FAISS] = None\n",
    ") -> FAISS:\n",
    "    \"\"\"\n",
    "    用文本 RAG 路线生成答案并入库，然后返回 FAISS 向量库。\n",
    "    bootstrap_db: 若传入，文本检索会优先引用该库的历史问答作为 retrieved context（冷启动可传 None）。\n",
    "    \"\"\"\n",
    "    docs = build_text_docs_with_answer(\n",
    "        questions=questions,\n",
    "        gen_pipe=gen_pipe,\n",
    "        add_prompt_snapshot=add_prompt_snapshot,\n",
    "        text_db=bootstrap_db,\n",
    "    )\n",
    "    print(docs)\n",
    "    return FAISS.from_documents(docs, emb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3966e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_once_mode(\n",
    "    question: str,\n",
    "    mode: str,                 # \"text\" or \"graph\"\n",
    "    gen_pipe,\n",
    "    tokenizer,\n",
    "    parser=None,\n",
    "    text_db: Optional[FAISS] = None,\n",
    "    graph_db: Optional[FAISS] = None,\n",
    "    *,\n",
    "    label: Optional[str] = None,\n",
    "    use_cuda_mem: bool = True,\n",
    ") -> Dict:\n",
    "    assert mode in (\"text\", \"graph\")\n",
    "\n",
    "    # 选择检索与prompt\n",
    "    if mode == \"text\":\n",
    "        retrieved_docs = None\n",
    "        if text_db and CONFIG.get(\"include_retrieved_context\", True):\n",
    "            _, hits = similarity_search_text_docs(question, text_db, k=CONFIG.get(\"faiss_search_k\", 3))\n",
    "            retrieved_docs = hits if hits else None\n",
    "        prompt = make_text_qa_prompt(question, retrieved_docs=retrieved_docs)\n",
    "    else:\n",
    "        retrieved_docs = None\n",
    "        if graph_db and CONFIG.get(\"include_retrieved_context\", True):\n",
    "            _, hits = similarity_search_graph_docs(question, parser, graph_db, k=CONFIG.get(\"faiss_search_k\", 3))\n",
    "            retrieved_docs = hits if hits else None\n",
    "        G, rels = parse_question_to_graph_generic(parser, question)\n",
    "        prompt = make_graph_qa_prompt(question, G, rels, retrieved_docs)\n",
    "\n",
    "    # token 计数\n",
    "    def _count_tokens(tokenizer, text: str) -> int:\n",
    "        return len(tokenizer.encode(text, add_special_tokens=False))\n",
    "\n",
    "    in_tok = _count_tokens(tokenizer, prompt)\n",
    "\n",
    "    # 计时 & 生成\n",
    "    peak_mem = None\n",
    "    if use_cuda_mem and torch.cuda.is_available():\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    out = gen_pipe(prompt)\n",
    "    dt = time.perf_counter() - t0\n",
    "\n",
    "    text = out[0][\"generated_text\"]\n",
    "    if CONFIG.get(\"return_full_text\", False):\n",
    "        answer = text[len(prompt):].strip()\n",
    "    else:\n",
    "        answer = text.strip()\n",
    "\n",
    "    out_tok = _count_tokens(tokenizer, answer)\n",
    "\n",
    "    if use_cuda_mem and torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "        peak_mem = torch.cuda.max_memory_allocated() / (1024**2)\n",
    "\n",
    "    return {\n",
    "        \"label\": label or f\"{mode}_rag\",\n",
    "        \"mode\": mode,\n",
    "        \"question\": question,\n",
    "        \"input_tokens\": in_tok,\n",
    "        \"output_tokens\": out_tok,\n",
    "        \"total_tokens\": in_tok + out_tok,\n",
    "        \"latency_sec\": dt,\n",
    "        \"peak_vram_MiB\": peak_mem,\n",
    "        \"prompt_chars\": len(prompt),\n",
    "        \"answer\": answer,\n",
    "        \"used_retrieval\": bool(retrieved_docs),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d847f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_compare_text_vs_graph(\n",
    "    questions: List[str],\n",
    "    gen_pipe, tokenizer, parser,\n",
    "    text_db: Optional[FAISS],\n",
    "    graph_db: Optional[FAISS],\n",
    ") -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for q in questions:\n",
    "        rows.append(\n",
    "            measure_once_mode(q, \"text\", gen_pipe, tokenizer, parser, text_db, graph_db, label=\"text_rag\")\n",
    "        )\n",
    "        rows.append(\n",
    "            measure_once_mode(q, \"graph\", gen_pipe, tokenizer, parser, text_db, graph_db, label=\"graph_rag\")\n",
    "        )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ---- 最小准确率工具（如你已有可忽略）----\n",
    "def _normalize_yesno(text: str) -> str:\n",
    "    if text is None: return \"NO\"\n",
    "    t = str(text).strip().lower()\n",
    "    if t == \"yes\" or (\"yes\" in t and \"no\" not in t): return \"YES\"\n",
    "    if t == \"no\"  or (\"no\"  in t and \"yes\" not in t): return \"NO\"\n",
    "    return \"NO\"\n",
    "\n",
    "def attach_gold(df: pd.DataFrame, gold_map: dict) -> pd.DataFrame:\n",
    "    g = pd.DataFrame(list(gold_map.items()), columns=[\"question\",\"gold\"])\n",
    "    g[\"gold\"] = g[\"gold\"].map(lambda x: \"YES\" if str(x).upper()==\"YES\" else \"NO\")\n",
    "    out = df.merge(g, on=\"question\", how=\"left\")\n",
    "    out[\"pred\"] = out[\"answer\"].map(_normalize_yesno)\n",
    "    out[\"correct\"] = (out[\"pred\"] == out[\"gold\"]).astype(int)\n",
    "    return out\n",
    "\n",
    "def evaluate_accuracy(df_with_gold: pd.DataFrame):\n",
    "    print(\"\\n== Accuracy by config ==\")\n",
    "    for k, sub in df_with_gold.groupby(\"label\"):\n",
    "        n = len(sub[sub[\"gold\"].notna()])\n",
    "        acc = sub[\"correct\"].mean() if n else float(\"nan\")\n",
    "        print(f\"{k:<10s} acc={acc:.3f} (n={n})\")\n",
    "\n",
    "def summarize_cost(df: pd.DataFrame, base_label: str, target_label: str):\n",
    "    A = df[df[\"label\"]==base_label]; B = df[df[\"label\"]==target_label]\n",
    "    def avg(col):\n",
    "        a, b = A[col].mean(), B[col].mean()\n",
    "        return a, b, (b-a)/max(1e-9,a)\n",
    "    print(\"\\n== Cost (avg) ==\")\n",
    "    for col in [\"input_tokens\",\"output_tokens\",\"total_tokens\",\"latency_sec\",\"peak_vram_MiB\",\"prompt_chars\"]:\n",
    "        if col in df.columns:\n",
    "            a,b,d = avg(col); print(f\"{col:>15s} | {base_label}: {a:8.2f} | {target_label}: {b:8.2f} | Δ%: {d*100:7.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9916527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_size_bytes(path: str) -> int:\n",
    "    total = 0\n",
    "    for root, _, files in os.walk(path):\n",
    "        for f in files:\n",
    "            fp = os.path.join(root, f)\n",
    "            try: total += os.path.getsize(fp)\n",
    "            except OSError: pass\n",
    "    return total\n",
    "\n",
    "def save_and_report_sizes(text_db: FAISS, graph_db: FAISS, text_dir=\"faiss_text_idx\", graph_dir=\"faiss_graph_idx\"):\n",
    "    text_db.save_local(text_dir)\n",
    "    graph_db.save_local(graph_dir)\n",
    "    def human(n):\n",
    "        u=[\"B\",\"KB\",\"MB\",\"GB\"]; i=0; x=float(n)\n",
    "        while x>=1024 and i<len(u)-1: x/=1024.0; i+=1\n",
    "        return f\"{x:.2f} {u[i]}\"\n",
    "    s_text  = dir_size_bytes(text_dir)\n",
    "    s_graph = dir_size_bytes(graph_dir)\n",
    "    print(f\"[Index size] text_rag  = {human(s_text)}  ({text_dir})\")\n",
    "    print(f\"[Index size] graph_rag = {human(s_graph)}  ({graph_dir})\")\n",
    "    return s_text, s_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e4e9e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.54it/s]\n",
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n",
      "YES\n",
      "NO\n",
      "NO\n",
      "YES\n",
      "NO\n",
      "YES\n",
      "YES\n",
      "NO\n",
      "NO\n",
      "[Document(metadata={'graph_id': 'Q1', 'question': 'Given that Earth completes a rotation approximately every 24 hours, does this rotation cause the Sun to appear to rise in the east and set in the west from the perspective of an observer on the surface?', 'num_nodes': 11, 'num_edges': 9, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'YES', 'created_at': 1756361420}, page_content='{\"e\":[\"Sun\",\"appear\",\"rise\",\"Earth\",\"complete\",\"rotation\",\"east\",\"set\",\"west\",\"perspective\",\"cause\"],\"r\":[\"subj\",\"obj\",\"prep_in\",\"prep_from\"],\"questions([[e,r,e], ...])\":[[0,0,1],[0,0,2],[3,0,4],[4,1,5],[6,0,7],[7,2,8],[7,3,9],[2,2,6],[5,0,10]]}'), Document(metadata={'graph_id': 'Q2', 'question': 'Based on basic human biology, which requires oxygen for cellular respiration and energy production, do humans need oxygen to survive under normal conditions?', 'num_nodes': 9, 'num_edges': 7, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'YES', 'created_at': 1756361421}, page_content='{\"e\":[\"need\",\"oxygen\",\"survive\",\"requires\",\"require\",\"normal conditions\",\"base\",\"basic human biology\",\"humans\"],\"r\":[\"obj\",\"subj\",\"prep_under\",\"prep_on\"],\"questions([[e,r,e], ...])\":[[0,0,1],[1,1,2],[3,1,4],[4,0,1],[2,2,5],[6,3,7],[8,1,0]]}'), Document(metadata={'graph_id': 'Q3', 'question': 'Although the Sahara Desert is one of the largest deserts in the world, is it located in the South American continent instead of Africa?', 'num_nodes': 3, 'num_edges': 2, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'NO', 'created_at': 1756361422}, page_content='{\"e\":[\"locate\",\"South American continent\",\"located\"],\"r\":[\"prep_in\",\"subj\"],\"questions([[e,r,e], ...])\":[[0,0,1],[2,1,0]]}'), Document(metadata={'graph_id': 'Q4', 'question': 'Considering the natural habitats of penguins, which are mainly located in the Southern Hemisphere, do penguins naturally live in the Arctic region alongside polar bears?', 'num_nodes': 6, 'num_edges': 4, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'NO', 'created_at': 1756361422}, page_content='{\"e\":[\"locate\",\"the Southern Hemisphere\",\"penguins\",\"live\",\"Arctic region\",\"located\"],\"r\":[\"prep_in\",\"subj\"],\"questions([[e,r,e], ...])\":[[0,0,1],[2,1,3],[3,0,4],[5,1,0]]}'), Document(metadata={'graph_id': 'Q5', 'question': 'Considering that Paris is the administrative and cultural center of France, is it also the official capital city of the country according to its constitution?', 'num_nodes': 6, 'num_edges': 4, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'YES', 'created_at': 1756361423}, page_content='{\"e\":[\"Paris\",\"consider\",\"accord\",\"its constitution\",\"it\",\"official capital city\"],\"r\":[\"subj\",\"prep_to\",\"isa\"],\"questions([[e,r,e], ...])\":[[0,0,1],[0,0,2],[2,1,3],[4,2,5]]}'), Document(metadata={'graph_id': 'Q6', 'question': 'Although gold is a dense and valuable metal, is its density greater than that of lead, making it heavier per cubic centimeter?', 'num_nodes': 2, 'num_edges': 1, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'NO', 'created_at': 1756361423}, page_content='{\"e\":[\"gold\",\"make\"],\"r\":[\"subj\"],\"questions([[e,r,e], ...])\":[[0,0,1]]}'), Document(metadata={'graph_id': 'Q7', 'question': 'Even though the Amazon River is among the longest rivers globally, is it actually longer than the Nile River when measured by official geographical surveys?', 'num_nodes': 0, 'num_edges': 0, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'YES', 'created_at': 1756361424}, page_content='__EMPTY_JSON__'), Document(metadata={'graph_id': 'Q8', 'question': \"Since the Moon is gravitationally bound to Earth and completes an orbit approximately every 27 days, is it classified as Earth's only natural satellite?\", 'num_nodes': 6, 'num_edges': 4, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'YES', 'created_at': 1756361425}, page_content='{\"e\":[\"classify\",\"Earth \\'s only natural satellite\",\"complete\",\"orbit\",\"Moon\",\"classified\"],\"r\":[\"prep_as\",\"obj\",\"subj\"],\"questions([[e,r,e], ...])\":[[0,0,1],[2,1,3],[4,2,2],[5,2,0]]}'), Document(metadata={'graph_id': 'Q9', 'question': 'Is the Earth, which orbits the Sun along with seven other planets in the solar system, generally considered to be round in shape despite its slight equatorial bulge?', 'num_nodes': 6, 'num_edges': 4, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'NO', 'created_at': 1756361425}, page_content='{\"e\":[\"Earth\",\"round in shape\",\"consider\",\"orbits\",\"orbit\",\"Sun\"],\"r\":[\"property\",\"subj\",\"obj\"],\"questions([[e,r,e], ...])\":[[0,0,1],[0,1,2],[3,1,4],[4,2,5]]}'), Document(metadata={'graph_id': 'Q10', 'question': 'Despite Tokyo being the largest city in Japan and a major global hub, is it the capital city of South Korea?', 'num_nodes': 2, 'num_edges': 1, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'NO', 'created_at': 1756361426}, page_content='{\"e\":[\"it\",\"capital city\"],\"r\":[\"isa\"],\"questions([[e,r,e], ...])\":[[0,0,1]]}')]\n",
      "[Document(metadata={'graph_id': 'Q1', 'question': 'Given that Earth completes a rotation approximately every 24 hours, does this rotation cause the Sun to appear to rise in the east and set in the west from the perspective of an observer on the surface?', 'num_nodes': 0, 'num_edges': 0, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'NO', 'created_at': 1756361431}, page_content='Given that Earth completes a rotation approximately every 24 hours, does this rotation cause the Sun to appear to rise in the east and set in the west from the perspective of an observer on the surface?'), Document(metadata={'graph_id': 'Q2', 'question': 'Based on basic human biology, which requires oxygen for cellular respiration and energy production, do humans need oxygen to survive under normal conditions?', 'num_nodes': 0, 'num_edges': 0, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'NO', 'created_at': 1756361431}, page_content='Based on basic human biology, which requires oxygen for cellular respiration and energy production, do humans need oxygen to survive under normal conditions?'), Document(metadata={'graph_id': 'Q3', 'question': 'Although the Sahara Desert is one of the largest deserts in the world, is it located in the South American continent instead of Africa?', 'num_nodes': 0, 'num_edges': 0, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'NO', 'created_at': 1756361431}, page_content='Although the Sahara Desert is one of the largest deserts in the world, is it located in the South American continent instead of Africa?'), Document(metadata={'graph_id': 'Q4', 'question': 'Considering the natural habitats of penguins, which are mainly located in the Southern Hemisphere, do penguins naturally live in the Arctic region alongside polar bears?', 'num_nodes': 0, 'num_edges': 0, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'NO', 'created_at': 1756361432}, page_content='Considering the natural habitats of penguins, which are mainly located in the Southern Hemisphere, do penguins naturally live in the Arctic region alongside polar bears?'), Document(metadata={'graph_id': 'Q5', 'question': 'Considering that Paris is the administrative and cultural center of France, is it also the official capital city of the country according to its constitution?', 'num_nodes': 0, 'num_edges': 0, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'YES', 'created_at': 1756361432}, page_content='Considering that Paris is the administrative and cultural center of France, is it also the official capital city of the country according to its constitution?'), Document(metadata={'graph_id': 'Q6', 'question': 'Although gold is a dense and valuable metal, is its density greater than that of lead, making it heavier per cubic centimeter?', 'num_nodes': 0, 'num_edges': 0, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'NO', 'created_at': 1756361432}, page_content='Although gold is a dense and valuable metal, is its density greater than that of lead, making it heavier per cubic centimeter?'), Document(metadata={'graph_id': 'Q7', 'question': 'Even though the Amazon River is among the longest rivers globally, is it actually longer than the Nile River when measured by official geographical surveys?', 'num_nodes': 0, 'num_edges': 0, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'NO', 'created_at': 1756361432}, page_content='Even though the Amazon River is among the longest rivers globally, is it actually longer than the Nile River when measured by official geographical surveys?'), Document(metadata={'graph_id': 'Q8', 'question': \"Since the Moon is gravitationally bound to Earth and completes an orbit approximately every 27 days, is it classified as Earth's only natural satellite?\", 'num_nodes': 0, 'num_edges': 0, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'YES', 'created_at': 1756361433}, page_content=\"Since the Moon is gravitationally bound to Earth and completes an orbit approximately every 27 days, is it classified as Earth's only natural satellite?\"), Document(metadata={'graph_id': 'Q9', 'question': 'Is the Earth, which orbits the Sun along with seven other planets in the solar system, generally considered to be round in shape despite its slight equatorial bulge?', 'num_nodes': 0, 'num_edges': 0, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'YES', 'created_at': 1756361433}, page_content='Is the Earth, which orbits the Sun along with seven other planets in the solar system, generally considered to be round in shape despite its slight equatorial bulge?'), Document(metadata={'graph_id': 'Q10', 'question': 'Despite Tokyo being the largest city in Japan and a major global hub, is it the capital city of South Korea?', 'num_nodes': 0, 'num_edges': 0, 'llm_model': 'microsoft/Phi-4-mini-reasoning', 'llm_answer': 'NO', 'created_at': 1756361433}, page_content='Despite Tokyo being the largest city in Japan and a major global hub, is it the capital city of South Korea?')]\n",
      "[Index size] text_rag  = 18.15 KB  (faiss_text_idx)\n",
      "[Index size] graph_rag = 19.58 KB  (faiss_graph_idx)\n",
      "\n",
      "== Accuracy by config ==\n",
      "graph_rag  acc=0.900 (n=10)\n",
      "text_rag   acc=0.600 (n=10)\n",
      "\n",
      "== Cost (avg) ==\n",
      "   input_tokens | text_rag:   183.20 | graph_rag:   449.10 | Δ%:  145.14%\n",
      "  output_tokens | text_rag:    26.00 | graph_rag:    27.80 | Δ%:    6.92%\n",
      "   total_tokens | text_rag:   209.20 | graph_rag:   476.90 | Δ%:  127.96%\n",
      "    latency_sec | text_rag:     2.49 | graph_rag:     3.10 | Δ%:   24.69%\n",
      "  peak_vram_MiB | text_rag:      nan | graph_rag:      nan | Δ%:     nan%\n",
      "   prompt_chars | text_rag:   843.90 | graph_rag:  1622.20 | Δ%:   92.23%\n"
     ]
    }
   ],
   "source": [
    "emb = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# 0) 模型与解析器\n",
    "gen_pipe, tokenizer = load_llm_pipeline()\n",
    "parser = RelationshipGraphParser()\n",
    "\n",
    "# 1) Graph RAG：你已有的流程\n",
    "graph_docs = build_docs_with_answer(\n",
    "    questions, parser, gen_pipe,\n",
    "    add_prompt_snapshot=False,\n",
    "    faiss_db=None  # 冷启动\n",
    ")\n",
    "print(graph_docs)\n",
    "graph_db = build_faiss_index(graph_docs)  # == 你已有 build_faiss_index\n",
    "\n",
    "# 2) Text RAG：并行构建（字段对齐）\n",
    "text_db = build_text_faiss_index_with_answers(\n",
    "    questions,\n",
    "    gen_pipe,\n",
    "    add_prompt_snapshot=False,\n",
    "    bootstrap_db=None  # 冷启动；也可传已有 text_db 做增量\n",
    ")\n",
    "\n",
    "# 3) 现在 text_db 与 graph_db 的 Document.metadata 键名一致，你可以直接复用你现有的\n",
    "#    度量、准确率与存储体积对比函数（比如 batch_compare_text_vs_graph / summarize_cost 等）\n",
    "\n",
    "\n",
    "# 2) 存储体积对比\n",
    "save_and_report_sizes(text_db, graph_db, text_dir=\"faiss_text_idx\", graph_dir=\"faiss_graph_idx\")\n",
    "\n",
    "# 3) 成本 & 准确率 A/B（用你现有 GOLD_LABELS）\n",
    "df_ab = batch_compare_text_vs_graph(questions, gen_pipe, tokenizer, parser, text_db, graph_db)\n",
    "df_ab_gold = attach_gold(df_ab, GOLD_LABELS)\n",
    "evaluate_accuracy(df_ab_gold)\n",
    "summarize_cost(df_ab_gold, base_label=\"text_rag\", target_label=\"graph_rag\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
